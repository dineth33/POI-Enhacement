{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936cfdec",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# CNN text classifcation model \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d60ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import time\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7128beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25161, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>clean_name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>vicinity</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>type_1</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Colombo Swimming Club</td>\n",
       "      <td>colombo swimming club</td>\n",
       "      <td>ChIJETFLQ0FZ4joRwioIp4MnzHA</td>\n",
       "      <td>148 “Storm Lodge” Galle Road 3</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>tourist_attraction</td>\n",
       "      <td>recreational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Storm lodge</td>\n",
       "      <td>storm lodge</td>\n",
       "      <td>ChIJGSU_sGtZ4joRiyZjgglUlPE</td>\n",
       "      <td>148 “Storm Lodge” Galle Road 3, Colombo 00300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lodging</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayura</td>\n",
       "      <td>ayura</td>\n",
       "      <td>ChIJQwy6bEFZ4joRU9m1ylxsbMs</td>\n",
       "      <td>142, Yathama Building, Galle Road, Colombo</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>jewelry_store</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baby Gallery Kurulapina</td>\n",
       "      <td>baby gallery kurulapina</td>\n",
       "      <td>ChIJR1dqFUFZ4joRsqACvaqRNws</td>\n",
       "      <td>WR8X+655, Colombo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clothing_store</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galle Face , Taj Hotel</td>\n",
       "      <td>galle face taj hotel</td>\n",
       "      <td>ChIJo015E0FZ4joRdGUr8gWxo4E</td>\n",
       "      <td>138 Colombo - Galle Main Road, Colombo</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44395</th>\n",
       "      <td>Ichiro Motoring - Wijerama</td>\n",
       "      <td>ichiro motoring wijerama</td>\n",
       "      <td>ChIJk3QsSX1a4joRDO-HD30GZT8</td>\n",
       "      <td>High Level Road, Nugegoda</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>car_repair</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44396</th>\n",
       "      <td>Softlogic Glomark Supermarket</td>\n",
       "      <td>softlogic glomark supermarket</td>\n",
       "      <td>ChIJD436Ynxb4joR_tn_grvgpNs</td>\n",
       "      <td>Nugegoda Delkanda Apartment, High Level Road, ...</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>grocery_or_supermarket</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44397</th>\n",
       "      <td>Softlogic Glomark Supermarket</td>\n",
       "      <td>softlogic glomark supermarket</td>\n",
       "      <td>ChIJD436Ynxb4joR_tn_grvgpNs</td>\n",
       "      <td>Nugegoda Delkanda Apartment, High Level Road, ...</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>grocery_or_supermarket</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44398</th>\n",
       "      <td>Mirai Auto Land (Pvt) Ltd</td>\n",
       "      <td>mirai auto land pvt ltd</td>\n",
       "      <td>ChIJ6V8_E2da4joREMxUiWN0uVA</td>\n",
       "      <td>Delkanda, 383 High Level Rd, Avissawella Road,...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>car_repair</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44399</th>\n",
       "      <td>Colombo Swimming Club</td>\n",
       "      <td>colombo swimming club</td>\n",
       "      <td>ChIJETFLQ0FZ4joRwioIp4MnzHA</td>\n",
       "      <td>148 “Storm Lodge” Galle Road 3</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>tourist_attraction</td>\n",
       "      <td>recreational</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25161 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name                     clean_name  \\\n",
       "0              Colombo Swimming Club          colombo swimming club   \n",
       "1                        Storm lodge                    storm lodge   \n",
       "5                              Ayura                          ayura   \n",
       "6            Baby Gallery Kurulapina        baby gallery kurulapina   \n",
       "7             Galle Face , Taj Hotel           galle face taj hotel   \n",
       "...                              ...                            ...   \n",
       "44395     Ichiro Motoring - Wijerama       ichiro motoring wijerama   \n",
       "44396  Softlogic Glomark Supermarket  softlogic glomark supermarket   \n",
       "44397  Softlogic Glomark Supermarket  softlogic glomark supermarket   \n",
       "44398      Mirai Auto Land (Pvt) Ltd        mirai auto land pvt ltd   \n",
       "44399          Colombo Swimming Club          colombo swimming club   \n",
       "\n",
       "                          place_id  \\\n",
       "0      ChIJETFLQ0FZ4joRwioIp4MnzHA   \n",
       "1      ChIJGSU_sGtZ4joRiyZjgglUlPE   \n",
       "5      ChIJQwy6bEFZ4joRU9m1ylxsbMs   \n",
       "6      ChIJR1dqFUFZ4joRsqACvaqRNws   \n",
       "7      ChIJo015E0FZ4joRdGUr8gWxo4E   \n",
       "...                            ...   \n",
       "44395  ChIJk3QsSX1a4joRDO-HD30GZT8   \n",
       "44396  ChIJD436Ynxb4joR_tn_grvgpNs   \n",
       "44397  ChIJD436Ynxb4joR_tn_grvgpNs   \n",
       "44398  ChIJ6V8_E2da4joREMxUiWN0uVA   \n",
       "44399  ChIJETFLQ0FZ4joRwioIp4MnzHA   \n",
       "\n",
       "                                                vicinity  no_of_ratings  \\\n",
       "0                         148 “Storm Lodge” Galle Road 3         1181.0   \n",
       "1          148 “Storm Lodge” Galle Road 3, Colombo 00300            NaN   \n",
       "5             142, Yathama Building, Galle Road, Colombo           16.0   \n",
       "6                                      WR8X+655, Colombo            NaN   \n",
       "7                 138 Colombo - Galle Main Road, Colombo            2.0   \n",
       "...                                                  ...            ...   \n",
       "44395                          High Level Road, Nugegoda           60.0   \n",
       "44396  Nugegoda Delkanda Apartment, High Level Road, ...         1278.0   \n",
       "44397  Nugegoda Delkanda Apartment, High Level Road, ...         1278.0   \n",
       "44398  Delkanda, 383 High Level Rd, Avissawella Road,...           52.0   \n",
       "44399                     148 “Storm Lodge” Galle Road 3         1181.0   \n",
       "\n",
       "       avg_rating                  type_1       purpose  \n",
       "0             4.4      tourist_attraction  recreational  \n",
       "1             NaN                 lodging      personal  \n",
       "5             4.5           jewelry_store      shopping  \n",
       "6             NaN          clothing_store      shopping  \n",
       "7             5.0              restaurant        dining  \n",
       "...           ...                     ...           ...  \n",
       "44395         3.5              car_repair      personal  \n",
       "44396         4.2  grocery_or_supermarket      shopping  \n",
       "44397         4.2  grocery_or_supermarket      shopping  \n",
       "44398         4.4              car_repair      personal  \n",
       "44399         4.4      tourist_attraction  recreational  \n",
       "\n",
       "[25161 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv(\"places_names_labelled.csv\", index_col = 0)\n",
    "# corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d76eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['purpose'].replace(corpus['purpose'].unique(), list(range(0, len(corpus['purpose'].unique()))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d482c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[~(corpus['purpose']==6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7b33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(corpus,corpus['purpose'],test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db40d3e",
   "metadata": {
    "id": "odRK28LIeAxn"
   },
   "source": [
    "\n",
    "<hr>\n",
    "\n",
    "A __standard model__ for document classification is to use (quoted from __Jason Brownlee__, the author of [machinelearningmastery.com](https://machinelearningmastery.com)):\n",
    ">- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    ">- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    ">- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "\n",
    "Therefore, the model is comprised of the following elements:\n",
    "- __Input layer__ that defines the length of input sequences.\n",
    "- __Embedding layer__ set to the size of the vocabulary and 100-dimensional real-valued representations.\n",
    "- __Conv1D layer__ with 32 filters and a kernel size set to the number of words to read at once.\n",
    "- __MaxPooling1D layer__ to consolidate the output from the convolutional layer.\n",
    "- __Flatten layer__ to reduce the three-dimensional output to two dimensional for concatenation.\n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 1-8.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- L2 Constraint: 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "We will perform the best parameter using __grid search__ and 10-fold cross validation.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2b2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb94e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  gateway asia travels\n",
      "Into a sequence of int: [600, 131, 30]\n",
      "Into a padded sequence: [600 131  30   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(X_train.clean_name)\n",
    "train_y = np.array(X_train.purpose)\n",
    "test_x = list(X_test.clean_name)\n",
    "test_y = np.array(X_test.purpose)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "print(\"Example of sentence: \", train_x[133])\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[133])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[133])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5766b461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "ltd 2\n",
      "pvt 3\n",
      "lanka 4\n",
      "the 5\n",
      "sri 6\n",
      "colombo 7\n",
      "of 8\n",
      "and 9\n",
      "bank 10\n",
      "12898\n"
     ]
    }
   ],
   "source": [
    "# See the first 10 words in the vocabulary\n",
    "word_index = tokenizer.word_index\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "        \n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bbe2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm(max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=8, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cd9a172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 300)          3869400   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 88        \n",
      "=================================================================\n",
      "Total params: 4,008,598\n",
      "Trainable params: 4,008,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model(input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=20, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)\n",
    "# callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d78d9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "385/385 - 22s - loss: 1.5778 - accuracy: 0.3972 - val_loss: 1.1691 - val_accuracy: 0.5952\n",
      "Epoch 2/60\n",
      "385/385 - 24s - loss: 1.2312 - accuracy: 0.5264 - val_loss: 1.0677 - val_accuracy: 0.6118\n",
      "Epoch 3/60\n",
      "385/385 - 23s - loss: 1.0543 - accuracy: 0.5953 - val_loss: 1.0137 - val_accuracy: 0.6047\n",
      "Epoch 4/60\n",
      "385/385 - 24s - loss: 0.9245 - accuracy: 0.6303 - val_loss: 0.9935 - val_accuracy: 0.6538\n",
      "Epoch 5/60\n",
      "385/385 - 23s - loss: 0.8553 - accuracy: 0.6447 - val_loss: 0.9907 - val_accuracy: 0.6484\n",
      "Epoch 6/60\n",
      "385/385 - 23s - loss: 0.7728 - accuracy: 0.6950 - val_loss: 1.0723 - val_accuracy: 0.6910\n",
      "Epoch 7/60\n",
      "385/385 - 24s - loss: 0.7394 - accuracy: 0.7163 - val_loss: 1.0583 - val_accuracy: 0.6850\n",
      "Epoch 8/60\n",
      "385/385 - 24s - loss: 0.7019 - accuracy: 0.7296 - val_loss: 1.0550 - val_accuracy: 0.6850\n",
      "Epoch 9/60\n",
      "385/385 - 24s - loss: 0.6959 - accuracy: 0.7253 - val_loss: 1.1276 - val_accuracy: 0.6802\n",
      "Epoch 10/60\n",
      "385/385 - 26s - loss: 0.6731 - accuracy: 0.7314 - val_loss: 1.1334 - val_accuracy: 0.6918\n",
      "Epoch 11/60\n",
      "385/385 - 25s - loss: 0.6515 - accuracy: 0.7423 - val_loss: 1.2794 - val_accuracy: 0.6966\n",
      "Epoch 12/60\n",
      "385/385 - 24s - loss: 0.6614 - accuracy: 0.7393 - val_loss: 1.2307 - val_accuracy: 0.6729\n",
      "Epoch 13/60\n",
      "385/385 - 24s - loss: 0.6480 - accuracy: 0.7405 - val_loss: 1.3025 - val_accuracy: 0.6960\n",
      "Epoch 14/60\n",
      "385/385 - 23s - loss: 0.6348 - accuracy: 0.7465 - val_loss: 1.3277 - val_accuracy: 0.6787\n",
      "Epoch 15/60\n",
      "385/385 - 23s - loss: 0.6345 - accuracy: 0.7458 - val_loss: 1.3609 - val_accuracy: 0.6935\n",
      "Epoch 16/60\n",
      "385/385 - 24s - loss: 0.6291 - accuracy: 0.7461 - val_loss: 1.3549 - val_accuracy: 0.7022\n",
      "Epoch 17/60\n",
      "385/385 - 23s - loss: 0.6346 - accuracy: 0.7416 - val_loss: 1.4709 - val_accuracy: 0.6951\n",
      "Epoch 18/60\n",
      "385/385 - 23s - loss: 0.6253 - accuracy: 0.7455 - val_loss: 1.4463 - val_accuracy: 0.6802\n",
      "Epoch 19/60\n",
      "385/385 - 24s - loss: 0.6185 - accuracy: 0.7476 - val_loss: 1.3576 - val_accuracy: 0.6766\n",
      "Epoch 20/60\n",
      "385/385 - 24s - loss: 0.6074 - accuracy: 0.7508 - val_loss: 1.5600 - val_accuracy: 0.6785\n",
      "Epoch 21/60\n",
      "385/385 - 24s - loss: 0.5945 - accuracy: 0.7553 - val_loss: 1.6030 - val_accuracy: 0.6856\n",
      "Epoch 22/60\n",
      "385/385 - 24s - loss: 0.5900 - accuracy: 0.7493 - val_loss: 1.5811 - val_accuracy: 0.6881\n",
      "Epoch 23/60\n",
      "385/385 - 25s - loss: 0.5714 - accuracy: 0.7575 - val_loss: 1.6560 - val_accuracy: 0.6906\n",
      "Epoch 24/60\n",
      "385/385 - 24s - loss: 0.5465 - accuracy: 0.7716 - val_loss: 1.6878 - val_accuracy: 0.6926\n",
      "Epoch 25/60\n",
      "385/385 - 27s - loss: 0.5348 - accuracy: 0.7786 - val_loss: 1.6238 - val_accuracy: 0.6968\n",
      "Epoch 26/60\n",
      "385/385 - 27s - loss: 0.5305 - accuracy: 0.7804 - val_loss: 1.8067 - val_accuracy: 0.6939\n",
      "Epoch 27/60\n",
      "385/385 - 26s - loss: 0.5223 - accuracy: 0.7901 - val_loss: 1.7377 - val_accuracy: 0.6899\n",
      "Epoch 28/60\n",
      "385/385 - 25s - loss: 0.5210 - accuracy: 0.7864 - val_loss: 1.9726 - val_accuracy: 0.6920\n",
      "Epoch 29/60\n",
      "385/385 - 26s - loss: 0.5282 - accuracy: 0.7826 - val_loss: 1.8780 - val_accuracy: 0.6912\n",
      "Epoch 30/60\n",
      "385/385 - 25s - loss: 0.5208 - accuracy: 0.7857 - val_loss: 1.8377 - val_accuracy: 0.6943\n",
      "Epoch 31/60\n",
      "385/385 - 28s - loss: 0.5310 - accuracy: 0.7833 - val_loss: 1.9416 - val_accuracy: 0.6901\n",
      "Epoch 32/60\n",
      "385/385 - 24s - loss: 0.5128 - accuracy: 0.7870 - val_loss: 2.0434 - val_accuracy: 0.6881\n",
      "Epoch 33/60\n",
      "385/385 - 27s - loss: 0.5134 - accuracy: 0.7877 - val_loss: 2.0175 - val_accuracy: 0.6891\n",
      "Epoch 34/60\n",
      "385/385 - 27s - loss: 0.5163 - accuracy: 0.7855 - val_loss: 1.9216 - val_accuracy: 0.6883\n",
      "Epoch 35/60\n",
      "385/385 - 25s - loss: 0.5151 - accuracy: 0.7905 - val_loss: 2.0853 - val_accuracy: 0.6993\n",
      "Epoch 36/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 24s - loss: 0.5126 - accuracy: 0.7899 - val_loss: 2.0029 - val_accuracy: 0.6893\n",
      "Epoch 00036: early stopping\n",
      "Test Accuracy: 70.22027969360352\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 43s - loss: 1.4961 - accuracy: 0.4166 - val_loss: 1.0721 - val_accuracy: 0.5877\n",
      "Epoch 2/60\n",
      "385/385 - 42s - loss: 1.1471 - accuracy: 0.5201 - val_loss: 0.9492 - val_accuracy: 0.6629\n",
      "Epoch 3/60\n",
      "385/385 - 42s - loss: 1.0037 - accuracy: 0.5777 - val_loss: 0.9091 - val_accuracy: 0.6741\n",
      "Epoch 4/60\n",
      "385/385 - 46s - loss: 0.9162 - accuracy: 0.6122 - val_loss: 0.9326 - val_accuracy: 0.6820\n",
      "Epoch 5/60\n",
      "385/385 - 44s - loss: 0.8641 - accuracy: 0.6315 - val_loss: 0.9526 - val_accuracy: 0.7205\n",
      "Epoch 6/60\n",
      "385/385 - 43s - loss: 0.8456 - accuracy: 0.6483 - val_loss: 0.9759 - val_accuracy: 0.7086\n",
      "Epoch 7/60\n",
      "385/385 - 43s - loss: 0.8165 - accuracy: 0.6655 - val_loss: 0.9978 - val_accuracy: 0.7097\n",
      "Epoch 8/60\n",
      "385/385 - 45s - loss: 0.8023 - accuracy: 0.6747 - val_loss: 1.0069 - val_accuracy: 0.7055\n",
      "Epoch 9/60\n",
      "385/385 - 45s - loss: 0.7869 - accuracy: 0.6847 - val_loss: 1.0872 - val_accuracy: 0.7078\n",
      "Epoch 10/60\n",
      "385/385 - 44s - loss: 0.7736 - accuracy: 0.6960 - val_loss: 1.1112 - val_accuracy: 0.7086\n",
      "Epoch 11/60\n",
      "385/385 - 44s - loss: 0.7563 - accuracy: 0.6965 - val_loss: 1.1706 - val_accuracy: 0.7078\n",
      "Epoch 12/60\n",
      "385/385 - 45s - loss: 0.7367 - accuracy: 0.7093 - val_loss: 1.2907 - val_accuracy: 0.7014\n",
      "Epoch 13/60\n",
      "385/385 - 44s - loss: 0.7309 - accuracy: 0.7078 - val_loss: 1.2837 - val_accuracy: 0.7226\n",
      "Epoch 14/60\n",
      "385/385 - 46s - loss: 0.6820 - accuracy: 0.7370 - val_loss: 1.3564 - val_accuracy: 0.6949\n",
      "Epoch 15/60\n",
      "385/385 - 46s - loss: 0.6438 - accuracy: 0.7540 - val_loss: 1.4106 - val_accuracy: 0.7124\n",
      "Epoch 16/60\n",
      "385/385 - 43s - loss: 0.6407 - accuracy: 0.7555 - val_loss: 1.5265 - val_accuracy: 0.7014\n",
      "Epoch 17/60\n",
      "385/385 - 44s - loss: 0.6246 - accuracy: 0.7652 - val_loss: 1.5988 - val_accuracy: 0.7249\n",
      "Epoch 18/60\n",
      "385/385 - 42s - loss: 0.6137 - accuracy: 0.7686 - val_loss: 1.6697 - val_accuracy: 0.7076\n",
      "Epoch 19/60\n",
      "385/385 - 41s - loss: 0.6177 - accuracy: 0.7643 - val_loss: 1.6168 - val_accuracy: 0.7161\n",
      "Epoch 20/60\n",
      "385/385 - 41s - loss: 0.6086 - accuracy: 0.7714 - val_loss: 1.5974 - val_accuracy: 0.7153\n",
      "Epoch 21/60\n",
      "385/385 - 41s - loss: 0.5863 - accuracy: 0.7658 - val_loss: 1.8613 - val_accuracy: 0.7186\n",
      "Epoch 22/60\n",
      "385/385 - 41s - loss: 0.5543 - accuracy: 0.7779 - val_loss: 1.7614 - val_accuracy: 0.7222\n",
      "Epoch 23/60\n",
      "385/385 - 41s - loss: 0.5525 - accuracy: 0.7816 - val_loss: 1.9841 - val_accuracy: 0.7138\n",
      "Epoch 24/60\n",
      "385/385 - 41s - loss: 0.5473 - accuracy: 0.7794 - val_loss: 1.9918 - val_accuracy: 0.7238\n",
      "Epoch 25/60\n",
      "385/385 - 41s - loss: 0.5496 - accuracy: 0.7744 - val_loss: 1.9797 - val_accuracy: 0.7273\n",
      "Epoch 26/60\n",
      "385/385 - 41s - loss: 0.5348 - accuracy: 0.7787 - val_loss: 1.9718 - val_accuracy: 0.7192\n",
      "Epoch 27/60\n",
      "385/385 - 41s - loss: 0.5283 - accuracy: 0.7770 - val_loss: 2.2120 - val_accuracy: 0.7217\n",
      "Epoch 28/60\n",
      "385/385 - 41s - loss: 0.5290 - accuracy: 0.7795 - val_loss: 2.3404 - val_accuracy: 0.7149\n",
      "Epoch 29/60\n",
      "385/385 - 41s - loss: 0.5263 - accuracy: 0.7822 - val_loss: 2.4468 - val_accuracy: 0.7186\n",
      "Epoch 30/60\n",
      "385/385 - 41s - loss: 0.5307 - accuracy: 0.7817 - val_loss: 2.2539 - val_accuracy: 0.7190\n",
      "Epoch 31/60\n",
      "385/385 - 41s - loss: 0.5277 - accuracy: 0.7796 - val_loss: 2.3322 - val_accuracy: 0.7219\n",
      "Epoch 32/60\n",
      "385/385 - 41s - loss: 0.5151 - accuracy: 0.7844 - val_loss: 2.2324 - val_accuracy: 0.7286\n",
      "Epoch 33/60\n",
      "385/385 - 41s - loss: 0.4989 - accuracy: 0.7791 - val_loss: 2.3294 - val_accuracy: 0.7201\n",
      "Epoch 34/60\n",
      "385/385 - 41s - loss: 0.4961 - accuracy: 0.7780 - val_loss: 2.4404 - val_accuracy: 0.7195\n",
      "Epoch 35/60\n",
      "385/385 - 41s - loss: 0.4833 - accuracy: 0.7803 - val_loss: 2.3656 - val_accuracy: 0.7290\n",
      "Epoch 36/60\n",
      "385/385 - 41s - loss: 0.4897 - accuracy: 0.7731 - val_loss: 2.2218 - val_accuracy: 0.7282\n",
      "Epoch 37/60\n",
      "385/385 - 41s - loss: 0.4802 - accuracy: 0.7810 - val_loss: 2.4434 - val_accuracy: 0.7303\n",
      "Epoch 38/60\n",
      "385/385 - 41s - loss: 0.4579 - accuracy: 0.7931 - val_loss: 2.4857 - val_accuracy: 0.7273\n",
      "Epoch 39/60\n",
      "385/385 - 41s - loss: 0.4639 - accuracy: 0.7916 - val_loss: 2.8899 - val_accuracy: 0.7286\n",
      "Epoch 40/60\n",
      "385/385 - 41s - loss: 0.4606 - accuracy: 0.7939 - val_loss: 2.6753 - val_accuracy: 0.7290\n",
      "Epoch 41/60\n",
      "385/385 - 41s - loss: 0.4504 - accuracy: 0.7962 - val_loss: 2.9403 - val_accuracy: 0.7261\n",
      "Epoch 42/60\n",
      "385/385 - 41s - loss: 0.4396 - accuracy: 0.8002 - val_loss: 2.7805 - val_accuracy: 0.7219\n",
      "Epoch 43/60\n",
      "385/385 - 41s - loss: 0.4347 - accuracy: 0.8012 - val_loss: 2.9218 - val_accuracy: 0.7273\n",
      "Epoch 44/60\n",
      "385/385 - 41s - loss: 0.4166 - accuracy: 0.8083 - val_loss: 3.1537 - val_accuracy: 0.7303\n",
      "Epoch 45/60\n",
      "385/385 - 41s - loss: 0.4223 - accuracy: 0.8049 - val_loss: 2.8356 - val_accuracy: 0.7292\n",
      "Epoch 46/60\n",
      "385/385 - 41s - loss: 0.4227 - accuracy: 0.8043 - val_loss: 3.1433 - val_accuracy: 0.7325\n",
      "Epoch 47/60\n",
      "385/385 - 41s - loss: 0.4194 - accuracy: 0.8042 - val_loss: 2.9235 - val_accuracy: 0.7257\n",
      "Epoch 48/60\n",
      "385/385 - 41s - loss: 0.4059 - accuracy: 0.8351 - val_loss: 3.1380 - val_accuracy: 0.7342\n",
      "Epoch 49/60\n",
      "385/385 - 41s - loss: 0.4012 - accuracy: 0.8350 - val_loss: 3.1628 - val_accuracy: 0.7307\n",
      "Epoch 50/60\n",
      "385/385 - 41s - loss: 0.3895 - accuracy: 0.8375 - val_loss: 3.4800 - val_accuracy: 0.7307\n",
      "Epoch 51/60\n",
      "385/385 - 41s - loss: 0.3694 - accuracy: 0.8460 - val_loss: 3.6389 - val_accuracy: 0.7294\n",
      "Epoch 52/60\n",
      "385/385 - 41s - loss: 0.3646 - accuracy: 0.8466 - val_loss: 3.6857 - val_accuracy: 0.7315\n",
      "Epoch 53/60\n",
      "385/385 - 41s - loss: 0.3755 - accuracy: 0.8476 - val_loss: 3.3894 - val_accuracy: 0.7271\n",
      "Epoch 54/60\n",
      "385/385 - 41s - loss: 0.3675 - accuracy: 0.8452 - val_loss: 3.4232 - val_accuracy: 0.7263\n",
      "Epoch 55/60\n",
      "385/385 - 41s - loss: 0.3558 - accuracy: 0.8514 - val_loss: 3.4401 - val_accuracy: 0.7249\n",
      "Epoch 56/60\n",
      "385/385 - 41s - loss: 0.3741 - accuracy: 0.8446 - val_loss: 3.7549 - val_accuracy: 0.7296\n",
      "Epoch 57/60\n",
      "385/385 - 41s - loss: 0.3648 - accuracy: 0.8488 - val_loss: 3.9127 - val_accuracy: 0.7271\n",
      "Epoch 58/60\n",
      "385/385 - 41s - loss: 0.3599 - accuracy: 0.8497 - val_loss: 3.8106 - val_accuracy: 0.7296\n",
      "Epoch 59/60\n",
      "385/385 - 41s - loss: 0.3623 - accuracy: 0.8611 - val_loss: 3.7891 - val_accuracy: 0.7261\n",
      "Epoch 60/60\n",
      "385/385 - 41s - loss: 0.3556 - accuracy: 0.8708 - val_loss: 3.2530 - val_accuracy: 0.7211\n",
      "Test Accuracy: 72.11138606071472\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 50s - loss: 1.7790 - accuracy: 0.3098 - val_loss: 1.4360 - val_accuracy: 0.4401\n",
      "Epoch 2/60\n",
      "385/385 - 50s - loss: 1.4944 - accuracy: 0.3991 - val_loss: 1.3141 - val_accuracy: 0.5829\n",
      "Epoch 3/60\n",
      "385/385 - 50s - loss: 1.3985 - accuracy: 0.4421 - val_loss: 1.2777 - val_accuracy: 0.4913\n",
      "Epoch 4/60\n",
      "385/385 - 56s - loss: 1.2837 - accuracy: 0.5015 - val_loss: 1.2863 - val_accuracy: 0.5927\n",
      "Epoch 5/60\n",
      "385/385 - 57s - loss: 1.1798 - accuracy: 0.5888 - val_loss: 1.2849 - val_accuracy: 0.5935\n",
      "Epoch 6/60\n",
      "385/385 - 60s - loss: 1.1245 - accuracy: 0.6098 - val_loss: 1.3688 - val_accuracy: 0.5916\n",
      "Epoch 7/60\n",
      "385/385 - 58s - loss: 1.0946 - accuracy: 0.6261 - val_loss: 1.4616 - val_accuracy: 0.5898\n",
      "Epoch 8/60\n",
      "385/385 - 53s - loss: 1.0735 - accuracy: 0.6369 - val_loss: 1.4889 - val_accuracy: 0.5970\n",
      "Epoch 9/60\n",
      "385/385 - 54s - loss: 1.0427 - accuracy: 0.6619 - val_loss: 1.6417 - val_accuracy: 0.5958\n",
      "Epoch 10/60\n",
      "385/385 - 51s - loss: 1.0210 - accuracy: 0.6679 - val_loss: 1.6570 - val_accuracy: 0.5740\n",
      "Epoch 11/60\n",
      "385/385 - 51s - loss: 1.0109 - accuracy: 0.6723 - val_loss: 1.6690 - val_accuracy: 0.5867\n",
      "Epoch 12/60\n",
      "385/385 - 51s - loss: 1.0052 - accuracy: 0.6717 - val_loss: 1.7909 - val_accuracy: 0.5700\n",
      "Epoch 13/60\n",
      "385/385 - 54s - loss: 0.9992 - accuracy: 0.6731 - val_loss: 1.8334 - val_accuracy: 0.5806\n",
      "Epoch 14/60\n",
      "385/385 - 57s - loss: 0.9924 - accuracy: 0.6767 - val_loss: 1.7409 - val_accuracy: 0.5752\n",
      "Epoch 15/60\n",
      "385/385 - 53s - loss: 0.9873 - accuracy: 0.6770 - val_loss: 1.8012 - val_accuracy: 0.5792\n",
      "Epoch 16/60\n",
      "385/385 - 54s - loss: 0.9843 - accuracy: 0.6761 - val_loss: 1.8333 - val_accuracy: 0.5692\n",
      "Epoch 17/60\n",
      "385/385 - 52s - loss: 0.9782 - accuracy: 0.6764 - val_loss: 2.0550 - val_accuracy: 0.5852\n",
      "Epoch 18/60\n",
      "385/385 - 56s - loss: 0.9793 - accuracy: 0.6757 - val_loss: 2.1170 - val_accuracy: 0.5821\n",
      "Epoch 19/60\n",
      "385/385 - 52s - loss: 0.9768 - accuracy: 0.6761 - val_loss: 2.4377 - val_accuracy: 0.5727\n",
      "Epoch 20/60\n",
      "385/385 - 56s - loss: 0.9773 - accuracy: 0.6770 - val_loss: 2.3022 - val_accuracy: 0.5713\n",
      "Epoch 21/60\n",
      "385/385 - 54s - loss: 0.9709 - accuracy: 0.6794 - val_loss: 2.0747 - val_accuracy: 0.5563\n",
      "Epoch 22/60\n",
      "385/385 - 54s - loss: 0.9681 - accuracy: 0.6785 - val_loss: 2.1874 - val_accuracy: 0.5563\n",
      "Epoch 23/60\n",
      "385/385 - 53s - loss: 0.9714 - accuracy: 0.6794 - val_loss: 2.2167 - val_accuracy: 0.5642\n",
      "Epoch 24/60\n",
      "385/385 - 50s - loss: 0.9707 - accuracy: 0.6771 - val_loss: 2.0252 - val_accuracy: 0.5578\n",
      "Epoch 25/60\n",
      "385/385 - 57s - loss: 0.9629 - accuracy: 0.6787 - val_loss: 2.5402 - val_accuracy: 0.5723\n",
      "Epoch 26/60\n",
      "385/385 - 56s - loss: 0.9630 - accuracy: 0.6795 - val_loss: 2.3721 - val_accuracy: 0.5621\n",
      "Epoch 27/60\n",
      "385/385 - 51s - loss: 0.9563 - accuracy: 0.6811 - val_loss: 2.2555 - val_accuracy: 0.5636\n",
      "Epoch 28/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 52s - loss: 0.9643 - accuracy: 0.6795 - val_loss: 2.4549 - val_accuracy: 0.5642\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 59.70490574836731\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 61s - loss: 1.9483 - accuracy: 0.3295 - val_loss: 1.8452 - val_accuracy: 0.3283\n",
      "Epoch 2/60\n",
      "385/385 - 60s - loss: 1.7726 - accuracy: 0.3347 - val_loss: 1.7265 - val_accuracy: 0.3283\n",
      "Epoch 3/60\n",
      "385/385 - 62s - loss: 1.6849 - accuracy: 0.3347 - val_loss: 1.6691 - val_accuracy: 0.3283\n",
      "Epoch 4/60\n",
      "385/385 - 60s - loss: 1.6417 - accuracy: 0.3347 - val_loss: 1.6409 - val_accuracy: 0.3283\n",
      "Epoch 5/60\n",
      "385/385 - 62s - loss: 1.6194 - accuracy: 0.3347 - val_loss: 1.6259 - val_accuracy: 0.3283\n",
      "Epoch 6/60\n",
      "385/385 - 60s - loss: 1.6068 - accuracy: 0.3347 - val_loss: 1.6174 - val_accuracy: 0.3283\n",
      "Epoch 7/60\n",
      "385/385 - 62s - loss: 1.5992 - accuracy: 0.3347 - val_loss: 1.6120 - val_accuracy: 0.3283\n",
      "Epoch 8/60\n",
      "385/385 - 62s - loss: 1.5943 - accuracy: 0.3347 - val_loss: 1.6083 - val_accuracy: 0.3283\n",
      "Epoch 9/60\n",
      "385/385 - 64s - loss: 1.5908 - accuracy: 0.3347 - val_loss: 1.6058 - val_accuracy: 0.3283\n",
      "Epoch 10/60\n",
      "385/385 - 66s - loss: 1.5883 - accuracy: 0.3347 - val_loss: 1.6039 - val_accuracy: 0.3283\n",
      "Epoch 11/60\n",
      "385/385 - 65s - loss: 1.5864 - accuracy: 0.3347 - val_loss: 1.6023 - val_accuracy: 0.3283\n",
      "Epoch 12/60\n",
      "385/385 - 64s - loss: 1.5849 - accuracy: 0.3347 - val_loss: 1.6011 - val_accuracy: 0.3283\n",
      "Epoch 13/60\n",
      "385/385 - 62s - loss: 1.5836 - accuracy: 0.3347 - val_loss: 1.6000 - val_accuracy: 0.3283\n",
      "Epoch 14/60\n",
      "385/385 - 61s - loss: 1.5826 - accuracy: 0.3347 - val_loss: 1.5992 - val_accuracy: 0.3283\n",
      "Epoch 15/60\n",
      "385/385 - 59s - loss: 1.5818 - accuracy: 0.3347 - val_loss: 1.5984 - val_accuracy: 0.3283\n",
      "Epoch 16/60\n",
      "385/385 - 60s - loss: 1.5811 - accuracy: 0.3347 - val_loss: 1.5977 - val_accuracy: 0.3283\n",
      "Epoch 17/60\n",
      "385/385 - 59s - loss: 1.5805 - accuracy: 0.3347 - val_loss: 1.5972 - val_accuracy: 0.3283\n",
      "Epoch 18/60\n",
      "385/385 - 59s - loss: 1.5800 - accuracy: 0.3347 - val_loss: 1.5967 - val_accuracy: 0.3283\n",
      "Epoch 19/60\n",
      "385/385 - 59s - loss: 1.5795 - accuracy: 0.3347 - val_loss: 1.5963 - val_accuracy: 0.3283\n",
      "Epoch 20/60\n",
      "385/385 - 59s - loss: 1.5792 - accuracy: 0.3347 - val_loss: 1.5959 - val_accuracy: 0.3283\n",
      "Epoch 21/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 59s - loss: 1.5789 - accuracy: 0.3347 - val_loss: 1.5956 - val_accuracy: 0.3283\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 32.83458054065704\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "3       relu       4  0.328346\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 24s - loss: 1.2811 - accuracy: 0.5633 - val_loss: 0.8224 - val_accuracy: 0.7398\n",
      "Epoch 2/60\n",
      "385/385 - 23s - loss: 0.7478 - accuracy: 0.7816 - val_loss: 0.7746 - val_accuracy: 0.7523\n",
      "Epoch 3/60\n",
      "385/385 - 26s - loss: 0.5415 - accuracy: 0.8437 - val_loss: 0.8144 - val_accuracy: 0.7469\n",
      "Epoch 4/60\n",
      "385/385 - 25s - loss: 0.4549 - accuracy: 0.8656 - val_loss: 0.8333 - val_accuracy: 0.7556\n",
      "Epoch 5/60\n",
      "385/385 - 25s - loss: 0.4098 - accuracy: 0.8741 - val_loss: 0.8696 - val_accuracy: 0.7529\n",
      "Epoch 6/60\n",
      "385/385 - 24s - loss: 0.3675 - accuracy: 0.8896 - val_loss: 0.8953 - val_accuracy: 0.7444\n",
      "Epoch 7/60\n",
      "385/385 - 25s - loss: 0.3397 - accuracy: 0.8980 - val_loss: 0.9683 - val_accuracy: 0.7454\n",
      "Epoch 8/60\n",
      "385/385 - 24s - loss: 0.3182 - accuracy: 0.9038 - val_loss: 0.9538 - val_accuracy: 0.7523\n",
      "Epoch 9/60\n",
      "385/385 - 24s - loss: 0.2942 - accuracy: 0.9080 - val_loss: 0.9571 - val_accuracy: 0.7539\n",
      "Epoch 10/60\n",
      "385/385 - 24s - loss: 0.2926 - accuracy: 0.9071 - val_loss: 0.9901 - val_accuracy: 0.7473\n",
      "Epoch 11/60\n",
      "385/385 - 24s - loss: 0.2772 - accuracy: 0.9126 - val_loss: 0.9994 - val_accuracy: 0.7452\n",
      "Epoch 12/60\n",
      "385/385 - 25s - loss: 0.2697 - accuracy: 0.9123 - val_loss: 1.0140 - val_accuracy: 0.7371\n",
      "Epoch 13/60\n",
      "385/385 - 25s - loss: 0.2559 - accuracy: 0.9186 - val_loss: 1.0280 - val_accuracy: 0.7500\n",
      "Epoch 14/60\n",
      "385/385 - 25s - loss: 0.2564 - accuracy: 0.9178 - val_loss: 1.0410 - val_accuracy: 0.7415\n",
      "Epoch 15/60\n",
      "385/385 - 24s - loss: 0.2522 - accuracy: 0.9193 - val_loss: 1.0466 - val_accuracy: 0.7461\n",
      "Epoch 16/60\n",
      "385/385 - 25s - loss: 0.2536 - accuracy: 0.9181 - val_loss: 1.0799 - val_accuracy: 0.7469\n",
      "Epoch 17/60\n",
      "385/385 - 26s - loss: 0.2430 - accuracy: 0.9193 - val_loss: 1.0994 - val_accuracy: 0.7454\n",
      "Epoch 18/60\n",
      "385/385 - 28s - loss: 0.2439 - accuracy: 0.9183 - val_loss: 1.0997 - val_accuracy: 0.7448\n",
      "Epoch 19/60\n",
      "385/385 - 26s - loss: 0.2347 - accuracy: 0.9187 - val_loss: 1.1598 - val_accuracy: 0.7415\n",
      "Epoch 20/60\n",
      "385/385 - 28s - loss: 0.2336 - accuracy: 0.9218 - val_loss: 1.1722 - val_accuracy: 0.7392\n",
      "Epoch 21/60\n",
      "385/385 - 25s - loss: 0.2367 - accuracy: 0.9201 - val_loss: 1.1438 - val_accuracy: 0.7382\n",
      "Epoch 22/60\n",
      "385/385 - 25s - loss: 0.2260 - accuracy: 0.9234 - val_loss: 1.1398 - val_accuracy: 0.7417\n",
      "Epoch 23/60\n",
      "385/385 - 24s - loss: 0.2248 - accuracy: 0.9212 - val_loss: 1.2306 - val_accuracy: 0.7382\n",
      "Epoch 24/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 24s - loss: 0.2158 - accuracy: 0.9263 - val_loss: 1.2184 - val_accuracy: 0.7298\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 75.56109428405762\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "3       relu       4  0.328346\n",
      "4       tanh       1  0.755611\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 45s - loss: 1.2768 - accuracy: 0.5449 - val_loss: 0.8747 - val_accuracy: 0.7205\n",
      "Epoch 2/60\n",
      "385/385 - 47s - loss: 0.7850 - accuracy: 0.7628 - val_loss: 0.7978 - val_accuracy: 0.7502\n",
      "Epoch 3/60\n",
      "385/385 - 44s - loss: 0.5650 - accuracy: 0.8280 - val_loss: 0.8242 - val_accuracy: 0.7473\n",
      "Epoch 4/60\n",
      "385/385 - 44s - loss: 0.4627 - accuracy: 0.8528 - val_loss: 0.8817 - val_accuracy: 0.7427\n",
      "Epoch 5/60\n",
      "385/385 - 46s - loss: 0.4023 - accuracy: 0.8712 - val_loss: 0.8923 - val_accuracy: 0.7492\n",
      "Epoch 6/60\n",
      "385/385 - 45s - loss: 0.3658 - accuracy: 0.8813 - val_loss: 0.8906 - val_accuracy: 0.7537\n",
      "Epoch 7/60\n",
      "385/385 - 47s - loss: 0.3428 - accuracy: 0.8855 - val_loss: 0.9272 - val_accuracy: 0.7508\n",
      "Epoch 8/60\n",
      "385/385 - 46s - loss: 0.3195 - accuracy: 0.8902 - val_loss: 0.9484 - val_accuracy: 0.7537\n",
      "Epoch 9/60\n",
      "385/385 - 47s - loss: 0.3125 - accuracy: 0.8916 - val_loss: 0.9931 - val_accuracy: 0.7500\n",
      "Epoch 10/60\n",
      "385/385 - 48s - loss: 0.2990 - accuracy: 0.8952 - val_loss: 1.0203 - val_accuracy: 0.7427\n",
      "Epoch 11/60\n",
      "385/385 - 43s - loss: 0.2847 - accuracy: 0.8968 - val_loss: 1.0241 - val_accuracy: 0.7452\n",
      "Epoch 12/60\n",
      "385/385 - 44s - loss: 0.2718 - accuracy: 0.8976 - val_loss: 1.0663 - val_accuracy: 0.7458\n",
      "Epoch 13/60\n",
      "385/385 - 47s - loss: 0.2759 - accuracy: 0.8978 - val_loss: 1.0966 - val_accuracy: 0.7471\n",
      "Epoch 14/60\n",
      "385/385 - 48s - loss: 0.2624 - accuracy: 0.9022 - val_loss: 1.0830 - val_accuracy: 0.7386\n",
      "Epoch 15/60\n",
      "385/385 - 49s - loss: 0.2499 - accuracy: 0.9094 - val_loss: 1.1374 - val_accuracy: 0.7442\n",
      "Epoch 16/60\n",
      "385/385 - 42s - loss: 0.2569 - accuracy: 0.9029 - val_loss: 1.1337 - val_accuracy: 0.7429\n",
      "Epoch 17/60\n",
      "385/385 - 42s - loss: 0.2499 - accuracy: 0.9035 - val_loss: 1.1641 - val_accuracy: 0.7477\n",
      "Epoch 18/60\n",
      "385/385 - 42s - loss: 0.2442 - accuracy: 0.9090 - val_loss: 1.1391 - val_accuracy: 0.7461\n",
      "Epoch 19/60\n",
      "385/385 - 42s - loss: 0.2382 - accuracy: 0.9062 - val_loss: 1.2053 - val_accuracy: 0.7197\n",
      "Epoch 20/60\n",
      "385/385 - 42s - loss: 0.2374 - accuracy: 0.9078 - val_loss: 1.3136 - val_accuracy: 0.7382\n",
      "Epoch 21/60\n",
      "385/385 - 43s - loss: 0.2368 - accuracy: 0.9097 - val_loss: 1.2346 - val_accuracy: 0.7458\n",
      "Epoch 22/60\n",
      "385/385 - 44s - loss: 0.2290 - accuracy: 0.9125 - val_loss: 1.2464 - val_accuracy: 0.7531\n",
      "Epoch 23/60\n",
      "385/385 - 47s - loss: 0.2345 - accuracy: 0.9078 - val_loss: 1.2141 - val_accuracy: 0.7340\n",
      "Epoch 24/60\n",
      "385/385 - 48s - loss: 0.2378 - accuracy: 0.9077 - val_loss: 1.2533 - val_accuracy: 0.7367\n",
      "Epoch 25/60\n",
      "385/385 - 44s - loss: 0.2277 - accuracy: 0.9093 - val_loss: 1.3015 - val_accuracy: 0.7350\n",
      "Epoch 26/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 44s - loss: 0.2320 - accuracy: 0.9061 - val_loss: 1.2586 - val_accuracy: 0.7300\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 75.3740668296814\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "3       relu       4  0.328346\n",
      "4       tanh       1  0.755611\n",
      "5       tanh       2  0.753741\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 58s - loss: 1.3131 - accuracy: 0.5154 - val_loss: 0.8790 - val_accuracy: 0.7300\n",
      "Epoch 2/60\n",
      "385/385 - 52s - loss: 0.8242 - accuracy: 0.7456 - val_loss: 0.7953 - val_accuracy: 0.7471\n",
      "Epoch 3/60\n",
      "385/385 - 50s - loss: 0.6065 - accuracy: 0.8151 - val_loss: 0.8013 - val_accuracy: 0.7438\n",
      "Epoch 4/60\n",
      "385/385 - 51s - loss: 0.4965 - accuracy: 0.8485 - val_loss: 0.8026 - val_accuracy: 0.7498\n",
      "Epoch 5/60\n",
      "385/385 - 50s - loss: 0.4316 - accuracy: 0.8638 - val_loss: 0.8447 - val_accuracy: 0.7506\n",
      "Epoch 6/60\n",
      "385/385 - 50s - loss: 0.3964 - accuracy: 0.8722 - val_loss: 0.8552 - val_accuracy: 0.7475\n",
      "Epoch 7/60\n",
      "385/385 - 50s - loss: 0.3666 - accuracy: 0.8821 - val_loss: 0.8796 - val_accuracy: 0.7554\n",
      "Epoch 8/60\n",
      "385/385 - 50s - loss: 0.3542 - accuracy: 0.8813 - val_loss: 0.9302 - val_accuracy: 0.7465\n",
      "Epoch 9/60\n",
      "385/385 - 51s - loss: 0.3297 - accuracy: 0.8888 - val_loss: 0.9529 - val_accuracy: 0.7438\n",
      "Epoch 10/60\n",
      "385/385 - 56s - loss: 0.3276 - accuracy: 0.8876 - val_loss: 0.9529 - val_accuracy: 0.7494\n",
      "Epoch 11/60\n",
      "385/385 - 53s - loss: 0.3067 - accuracy: 0.8971 - val_loss: 1.0156 - val_accuracy: 0.7477\n",
      "Epoch 12/60\n",
      "385/385 - 51s - loss: 0.3044 - accuracy: 0.8919 - val_loss: 1.0425 - val_accuracy: 0.7471\n",
      "Epoch 13/60\n",
      "385/385 - 51s - loss: 0.3022 - accuracy: 0.8929 - val_loss: 1.0585 - val_accuracy: 0.7490\n",
      "Epoch 14/60\n",
      "385/385 - 50s - loss: 0.2936 - accuracy: 0.8955 - val_loss: 1.0255 - val_accuracy: 0.7471\n",
      "Epoch 15/60\n",
      "385/385 - 50s - loss: 0.2905 - accuracy: 0.8984 - val_loss: 1.1087 - val_accuracy: 0.7431\n",
      "Epoch 16/60\n",
      "385/385 - 51s - loss: 0.2780 - accuracy: 0.8983 - val_loss: 1.1163 - val_accuracy: 0.7427\n",
      "Epoch 17/60\n",
      "385/385 - 50s - loss: 0.2713 - accuracy: 0.9021 - val_loss: 1.1100 - val_accuracy: 0.7485\n",
      "Epoch 18/60\n",
      "385/385 - 51s - loss: 0.2650 - accuracy: 0.9048 - val_loss: 1.1294 - val_accuracy: 0.7442\n",
      "Epoch 19/60\n",
      "385/385 - 50s - loss: 0.2665 - accuracy: 0.9017 - val_loss: 1.1739 - val_accuracy: 0.7431\n",
      "Epoch 20/60\n",
      "385/385 - 50s - loss: 0.2733 - accuracy: 0.8992 - val_loss: 1.1773 - val_accuracy: 0.7427\n",
      "Epoch 21/60\n",
      "385/385 - 50s - loss: 0.2605 - accuracy: 0.9011 - val_loss: 1.1416 - val_accuracy: 0.7502\n",
      "Epoch 22/60\n",
      "385/385 - 50s - loss: 0.2546 - accuracy: 0.9053 - val_loss: 1.1802 - val_accuracy: 0.7485\n",
      "Epoch 23/60\n",
      "385/385 - 50s - loss: 0.2392 - accuracy: 0.9100 - val_loss: 1.2288 - val_accuracy: 0.7415\n",
      "Epoch 24/60\n",
      "385/385 - 51s - loss: 0.2504 - accuracy: 0.9026 - val_loss: 1.2166 - val_accuracy: 0.7465\n",
      "Epoch 25/60\n",
      "385/385 - 50s - loss: 0.2495 - accuracy: 0.9055 - val_loss: 1.2325 - val_accuracy: 0.7392\n",
      "Epoch 26/60\n",
      "385/385 - 50s - loss: 0.2522 - accuracy: 0.9023 - val_loss: 1.2585 - val_accuracy: 0.7458\n",
      "Epoch 27/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 51s - loss: 0.2510 - accuracy: 0.9045 - val_loss: 1.2913 - val_accuracy: 0.7379\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 75.54031610488892\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "3       relu       4  0.328346\n",
      "4       tanh       1  0.755611\n",
      "5       tanh       2  0.753741\n",
      "6       tanh       3  0.755403\n",
      "\n",
      "Epoch 1/60\n",
      "385/385 - 61s - loss: 1.2599 - accuracy: 0.5790 - val_loss: 0.8252 - val_accuracy: 0.7463\n",
      "Epoch 2/60\n",
      "385/385 - 70s - loss: 0.7323 - accuracy: 0.7971 - val_loss: 0.8153 - val_accuracy: 0.7444\n",
      "Epoch 3/60\n",
      "385/385 - 70s - loss: 0.5306 - accuracy: 0.8570 - val_loss: 0.8502 - val_accuracy: 0.7512\n",
      "Epoch 4/60\n",
      "385/385 - 68s - loss: 0.4311 - accuracy: 0.8839 - val_loss: 0.8861 - val_accuracy: 0.7485\n",
      "Epoch 5/60\n",
      "385/385 - 64s - loss: 0.3748 - accuracy: 0.8984 - val_loss: 0.9188 - val_accuracy: 0.7562\n",
      "Epoch 6/60\n",
      "385/385 - 62s - loss: 0.3361 - accuracy: 0.9056 - val_loss: 0.9957 - val_accuracy: 0.7446\n",
      "Epoch 7/60\n",
      "385/385 - 61s - loss: 0.3109 - accuracy: 0.9149 - val_loss: 1.0030 - val_accuracy: 0.7469\n",
      "Epoch 8/60\n",
      "385/385 - 61s - loss: 0.2856 - accuracy: 0.9177 - val_loss: 1.0126 - val_accuracy: 0.7319\n",
      "Epoch 9/60\n",
      "385/385 - 61s - loss: 0.2736 - accuracy: 0.9233 - val_loss: 1.0720 - val_accuracy: 0.7488\n",
      "Epoch 10/60\n",
      "385/385 - 61s - loss: 0.2635 - accuracy: 0.9232 - val_loss: 1.0578 - val_accuracy: 0.7288\n",
      "Epoch 11/60\n",
      "385/385 - 60s - loss: 0.2547 - accuracy: 0.9252 - val_loss: 1.0879 - val_accuracy: 0.7267\n",
      "Epoch 12/60\n",
      "385/385 - 60s - loss: 0.2355 - accuracy: 0.9322 - val_loss: 1.1372 - val_accuracy: 0.7431\n",
      "Epoch 13/60\n",
      "385/385 - 60s - loss: 0.2336 - accuracy: 0.9293 - val_loss: 1.1131 - val_accuracy: 0.7448\n",
      "Epoch 14/60\n",
      "385/385 - 60s - loss: 0.2235 - accuracy: 0.9344 - val_loss: 1.1824 - val_accuracy: 0.7458\n",
      "Epoch 15/60\n",
      "385/385 - 60s - loss: 0.2220 - accuracy: 0.9337 - val_loss: 1.1432 - val_accuracy: 0.7498\n",
      "Epoch 16/60\n",
      "385/385 - 61s - loss: 0.2210 - accuracy: 0.9333 - val_loss: 1.2665 - val_accuracy: 0.7342\n",
      "Epoch 17/60\n",
      "385/385 - 61s - loss: 0.2120 - accuracy: 0.9365 - val_loss: 1.2340 - val_accuracy: 0.7440\n",
      "Epoch 18/60\n",
      "385/385 - 61s - loss: 0.2106 - accuracy: 0.9373 - val_loss: 1.1863 - val_accuracy: 0.7512\n",
      "Epoch 19/60\n",
      "385/385 - 61s - loss: 0.2060 - accuracy: 0.9391 - val_loss: 1.2584 - val_accuracy: 0.7417\n",
      "Epoch 20/60\n",
      "385/385 - 61s - loss: 0.1967 - accuracy: 0.9398 - val_loss: 1.2618 - val_accuracy: 0.7423\n",
      "Epoch 21/60\n",
      "385/385 - 61s - loss: 0.1940 - accuracy: 0.9398 - val_loss: 1.2099 - val_accuracy: 0.7465\n",
      "Epoch 22/60\n",
      "385/385 - 60s - loss: 0.1934 - accuracy: 0.9390 - val_loss: 1.2953 - val_accuracy: 0.7342\n",
      "Epoch 23/60\n",
      "385/385 - 60s - loss: 0.1917 - accuracy: 0.9381 - val_loss: 1.3081 - val_accuracy: 0.7309\n",
      "Epoch 24/60\n",
      "385/385 - 60s - loss: 0.1954 - accuracy: 0.9379 - val_loss: 1.2935 - val_accuracy: 0.7473\n",
      "Epoch 25/60\n",
      "Restoring model weights from the end of the best epoch.\n",
      "385/385 - 61s - loss: 0.1893 - accuracy: 0.9411 - val_loss: 1.2851 - val_accuracy: 0.7280\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 75.62344074249268\n",
      "\n",
      "  Activation Filters       Acc\n",
      "0       relu       1  0.702203\n",
      "1       relu       2  0.721114\n",
      "2       relu       3  0.597049\n",
      "3       relu       4  0.328346\n",
      "4       tanh       1  0.755611\n",
      "5       tanh       2  0.753741\n",
      "6       tanh       3  0.755403\n",
      "7       tanh       4  0.756234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu', 'tanh']\n",
    "filters = 1000\n",
    "kernel_sizes = [1, 2, 3, 4]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'Acc']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "train_x = list(X_train.clean_name)\n",
    "train_y = np.array(X_train.purpose)\n",
    "test_x = list(X_test.clean_name)\n",
    "test_y = np.array(X_test.purpose)\n",
    "\n",
    "for activation in activations:\n",
    "\n",
    "    for kernel_size in kernel_sizes:\n",
    "\n",
    "        # encode data using\n",
    "        # Cleaning and Tokenization\n",
    "        tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "        tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "        # Turn the text into sequence\n",
    "        training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "        test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "        max_len = max_length(training_sequences)\n",
    "\n",
    "        # Pad the sequence to have the same size\n",
    "        Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "        Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "        word_index = tokenizer.word_index\n",
    "        vocab_size = len(word_index)+1\n",
    "\n",
    "        # Define the input shape\n",
    "        model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(Xtrain, train_y, batch_size=50, epochs=60, verbose=2, \n",
    "                  callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "        # evaluate the model\n",
    "        loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "        print('Test Accuracy: {}'.format(acc*100))\n",
    "        \n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + [acc]\n",
    "        \n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        \n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe238d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
